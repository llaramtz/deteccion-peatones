{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from joblib import load\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1077300 features, but SVC is expecting 2112 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 47>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     48\u001B[0m ret, frame \u001B[38;5;241m=\u001B[39m cap\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;241m==\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m---> 51\u001B[0m     line_frame \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_frame\u001B[49m\u001B[43m(\u001B[49m\u001B[43mframe\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m     cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVideo\u001B[39m\u001B[38;5;124m'\u001B[39m, line_frame)\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;66;03m# Salir al presionar la tecla 'q'\u001B[39;00m\n",
      "Input \u001B[0;32mIn [10]\u001B[0m, in \u001B[0;36mprocess_frame\u001B[0;34m(frame)\u001B[0m\n\u001B[1;32m     31\u001B[0m descriptor \u001B[38;5;241m=\u001B[39m hog\u001B[38;5;241m.\u001B[39mcompute(gray)\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Realizar la predicción utilizando el modelo SVM\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m _, result \u001B[38;5;241m=\u001B[39m \u001B[43msvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdescriptor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m#_, result = svm.predict(hog_accum_adjusted)\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \n\u001B[1;32m     38\u001B[0m \u001B[38;5;66;03m# Obtener las coordenadas del rectángulo del peatón detectado\u001B[39;00m\n\u001B[1;32m     39\u001B[0m x, y, w, h \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mravel()\n",
      "File \u001B[0;32m~/.conda/envs/pythonProject2/lib/python3.10/site-packages/sklearn/svm/_base.py:810\u001B[0m, in \u001B[0;36mBaseSVC.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    808\u001B[0m     y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecision_function(X), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    809\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 810\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(np\u001B[38;5;241m.\u001B[39masarray(y, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mintp))\n",
      "File \u001B[0;32m~/.conda/envs/pythonProject2/lib/python3.10/site-packages/sklearn/svm/_base.py:433\u001B[0m, in \u001B[0;36mBaseLibSVM.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;124;03m\"\"\"Perform regression on samples in X.\u001B[39;00m\n\u001B[1;32m    419\u001B[0m \n\u001B[1;32m    420\u001B[0m \u001B[38;5;124;03m    For an one-class model, +1 (inlier) or -1 (outlier) is returned.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;124;03m        The predicted values.\u001B[39;00m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 433\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_for_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    434\u001B[0m     predict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse_predict \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dense_predict\n\u001B[1;32m    435\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m predict(X)\n",
      "File \u001B[0;32m~/.conda/envs/pythonProject2/lib/python3.10/site-packages/sklearn/svm/_base.py:611\u001B[0m, in \u001B[0;36mBaseLibSVM._validate_for_predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    608\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    610\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel):\n\u001B[0;32m--> 611\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    612\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    613\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    614\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat64\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    615\u001B[0m \u001B[43m        \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    616\u001B[0m \u001B[43m        \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    617\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    618\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m sp\u001B[38;5;241m.\u001B[39misspmatrix(X):\n\u001B[1;32m    621\u001B[0m     X \u001B[38;5;241m=\u001B[39m sp\u001B[38;5;241m.\u001B[39mcsr_matrix(X)\n",
      "File \u001B[0;32m~/.conda/envs/pythonProject2/lib/python3.10/site-packages/sklearn/base.py:600\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    597\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    599\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 600\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    602\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/.conda/envs/pythonProject2/lib/python3.10/site-packages/sklearn/base.py:400\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    399\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[0;32m--> 400\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    401\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    402\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    403\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: X has 1077300 features, but SVC is expecting 2112 features as input."
     ]
    }
   ],
   "source": [
    "# Abrir el archivo de video\n",
    "#cap = cv2.VideoCapture('video/crosswalk.avi')\n",
    "cap = cv2.VideoCapture('video/fourway.avi')\n",
    "\n",
    "# Definir los puntos de referencia de la ROI para detección de carriles\n",
    "#ROI_vertices = [(0, 720), (1280, 720), (800, 450), (580, 450)]\n",
    "height, width = cap.read()[1].shape[:2]\n",
    "ROI_vertices = [(200, height), (1100,height), (550, 250)]\n",
    "\n",
    "\n",
    "svm = load('modelo_svm.xml')  # Cargar el modelo entrenado del archivo\n",
    "\n",
    "\n",
    "def draw_lines(img, lines):\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), thickness=2)\n",
    "\n",
    "\n",
    "def process_frame(frame):\n",
    "    hog_accum = []\n",
    "\n",
    "    resized_frame = cv2.resize(frame, (210, 240))\n",
    "\n",
    "    # Convertir la imagen a escala de grises\n",
    "    gray = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    hog_feature, hog_img = hog(gray,\n",
    "                                               orientations = 11,\n",
    "                                               pixels_per_cell = (16,16),\n",
    "                                               cells_per_block = (2,2),\n",
    "                                               transform_sqrt = False,\n",
    "                                               visualize = True,\n",
    "                                               feature_vector = True)\n",
    "\n",
    "    hog_accum.append(hog_feature)\n",
    "\n",
    "    # Ajustar dimensiones de los arrays en pedestrian_hog_accum\n",
    "    min_shape = min(arr.shape[0] for arr in hog_accum)\n",
    "    hog_accum_adjusted = [arr[:min_shape] for arr in hog_accum]\n",
    "\n",
    "    # Calcular el descriptor HOG de la imagen\n",
    "    #descriptor = hog.compute(gray)\n",
    "\n",
    "    # Ajustar las dimensiones del descriptor\n",
    "    #descriptor = descriptor.reshape(1, -1)\n",
    "\n",
    "    # Convertir el descriptor a tipo CV_32F\n",
    "    #descriptor = descriptor.astype(np.float32)\n",
    "\n",
    "    # Realizar la predicción utilizando el modelo SVM\n",
    "    _, result = svm.predict(hog_accum_adjusted)\n",
    "\n",
    "    # Obtener las coordenadas del rectángulo del peatón detectado\n",
    "    x, y, w, h = result.ravel()\n",
    "\n",
    "    # Dibujar un rectángulo alrededor del peatón detectado\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), thickness=2)\n",
    "\n",
    "    return frame\n",
    "\n",
    "# Procesar cada cuadro del video y mostrar la imagen de salida\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret == True:\n",
    "        line_frame = process_frame(frame)\n",
    "        cv2.imshow('Video', line_frame)\n",
    "\n",
    "        # Salir al presionar la tecla 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
